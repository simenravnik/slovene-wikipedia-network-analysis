{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import, division, print_function\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Model, layers\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/train_test_spit.json\", \"r\") as f:\n",
    "    split = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILENAME = os.path.join(\"..\", \"..\", \"data\", \"wikilinks_train.emb\")\n",
    "embeddings = np.genfromtxt(EMBEDDING_FILENAME, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142930"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(split[\"train\"][\"1\"]) * 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_1 = random.sample(split[\"train\"][\"1\"], int(len(split[\"train\"][\"1\"]) * 0.02))\n",
    "tr_0 = random.sample(split[\"train\"][\"0\"], int(len(split[\"train\"][\"0\"]) * 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_1 = random.sample(split[\"test\"][\"1\"], int(len(split[\"test\"][\"1\"]) * 0.02))\n",
    "te_0 = random.sample(split[\"test\"][\"0\"], int(len(split[\"test\"][\"0\"]) * 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sem tu\n"
     ]
    }
   ],
   "source": [
    "with open(\"train.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for i, j in tr_1:\n",
    "        writer.writerow(np.concatenate((embeddings[i], embeddings[j], np.array([1])), axis=0))\n",
    "    print(\"sem tu\")\n",
    "    for i, j in tr_0:\n",
    "        writer.writerow(np.concatenate((embeddings[i], embeddings[j], np.array([0])), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sem tu\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for i, j in te_1:\n",
    "        writer.writerow(np.concatenate((embeddings[i], embeddings[j], np.array([1])), axis=0))\n",
    "    print(\"sem tu\")\n",
    "    for i, j in te_0:\n",
    "        writer.writerow(np.concatenate((embeddings[i], embeddings[j], np.array([0])), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in split[\"train\"][\"0\"]:\n",
    "    train.append(list(np.concatenate((embeddings[i], embeddings[j]), axis=0)))\n",
    "    train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(range(len(embeddings[0])*2))\n",
    "columns.append(\"label\")\n",
    "\n",
    "train  = pd.DataFrame(columns=columns)\n",
    "test  = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 257 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000022?line=1'>2</a>\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(np\u001b[39m.\u001b[39mconcatenate((embeddings[i], embeddings[j]), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000022?line=2'>3</a>\u001b[0m row[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simenravnik/Documents/FRI/Masters/1.Letnik/2.Semester/INA/project/src/link_prediction/link_prediction.ipynb#ch0000022?line=3'>4</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([train,  pd\u001b[39m.\u001b[39;49mDataFrame(row, index\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m])], ignore_index \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, axis \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py:360\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=155'>156</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=156'>157</a>\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=157'>158</a>\u001b[0m \u001b[39malong the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=344'>345</a>\u001b[0m \u001b[39mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=345'>346</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=346'>347</a>\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=347'>348</a>\u001b[0m     objs,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=348'>349</a>\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=356'>357</a>\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=357'>358</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=359'>360</a>\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py:595\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=590'>591</a>\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=592'>593</a>\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=594'>595</a>\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=595'>596</a>\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=596'>597</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=597'>598</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/reshape/concat.py?line=598'>599</a>\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py:241\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=238'>239</a>\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=239'>240</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=240'>241</a>\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=241'>242</a>\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=243'>244</a>\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py:495\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=491'>492</a>\u001b[0m     concat_values \u001b[39m=\u001b[39m ensure_block_shape(concat_values, \u001b[39m2\u001b[39m)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=493'>494</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=494'>495</a>\u001b[0m     concat_values \u001b[39m=\u001b[39m concat_compat(to_concat, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/internals/concat.py?line=496'>497</a>\u001b[0m \u001b[39mreturn\u001b[39;00m concat_values\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=147'>148</a>\u001b[0m             to_concat \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat]\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=148'>149</a>\u001b[0m             kinds \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mo\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=150'>151</a>\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(to_concat, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=151'>152</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kinds \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=152'>153</a>\u001b[0m     \u001b[39m# GH#39817\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=153'>154</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=154'>155</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=155'>156</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=159'>160</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/ina2/lib/python3.9/site-packages/pandas/core/dtypes/concat.py?line=160'>161</a>\u001b[0m     )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, j in split[\"train\"][\"1\"]:\n",
    "    row = dict(enumerate(np.concatenate((embeddings[i], embeddings[j]), axis=0)))\n",
    "    row[\"label\"] = 1\n",
    "    train = pd.concat([train,  pd.DataFrame(row, index=[0])], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset( embeddings, links, class_):\n",
    "    for i, j in links:\n",
    "        row = dict(enumerate(np.concatenate((embeddings[i], embeddings[j]), axis=0)))\n",
    "        row[\"label\"] = class_\n",
    "        break\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "X_train, y_train = construct_dataset(X_train, y_train, embeddings, split[\"train\"][\"1\"], 1)\n",
    "X_train, y_train = construct_dataset(X_train, y_train, embeddings, split[\"train\"][\"0\"], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train', 'w') as f:\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    write.writerows(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1 # Link exists or not\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.001\n",
    "training_steps = 200\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network parameters.\n",
    "conv1_filters = 32 # number of filters for 1st conv layer.\n",
    "conv2_filters = 64 # number of filters for 2nd conv layer.\n",
    "fc1_units = 1024 # number of neurons for 1st fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class ConvNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5.\n",
    "        self.conv1 = layers.Conv1D(32, kernel_size=5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2. \n",
    "        self.maxpool1 = layers.MaxPool1D(2, strides=2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3.\n",
    "        self.conv2 = layers.Conv1D(64, kernel_size=3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2. \n",
    "        self.maxpool2 = layers.MaxPool1D(2, strides=2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer.\n",
    "        self.flatten = layers.Flatten()\n",
    "\n",
    "        # Fully connected layer.\n",
    "        self.fc1 = layers.Dense(1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied).\n",
    "        self.dropout = layers.Dropout(rate=0.5)\n",
    "\n",
    "        # Output layer, class prediction.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x, training=is_training)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network model.\n",
    "conv_net = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = conv_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = conv_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = conv_net(batch_x)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on validation set.\n",
    "pred = conv_net(X_test)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4436c7e962e949d150c76746916f0dd543f0521219d740f210ff6e4096d070"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ina2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
